<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Linear Systems · VLDataScienceMachineLearningPackage</title><meta name="title" content="Linear Systems · VLDataScienceMachineLearningPackage"/><meta property="og:title" content="Linear Systems · VLDataScienceMachineLearningPackage"/><meta property="twitter:title" content="Linear Systems · VLDataScienceMachineLearningPackage"/><meta name="description" content="Documentation for VLDataScienceMachineLearningPackage."/><meta property="og:description" content="Documentation for VLDataScienceMachineLearningPackage."/><meta property="twitter:description" content="Documentation for VLDataScienceMachineLearningPackage."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">VLDataScienceMachineLearningPackage</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../data/">Data</a></li><li><a class="tocitem" href="../types/">Types</a></li><li><a class="tocitem" href="../factory/">Factory</a></li><li><a class="tocitem" href="../text/">Text</a></li><li><a class="tocitem" href="../wolfram/">Wolfram</a></li><li><a class="tocitem" href="../graphs/">Graphs</a></li><li class="is-active"><a class="tocitem" href>Linear Systems</a></li><li><a class="tocitem" href="../binaryclassification/">Binary Classification</a></li><li><span class="tocitem">Reinforcement Learning</span><ul><li><a class="tocitem" href="../mdp/">Markov Decision Processes</a></li><li><a class="tocitem" href="../bandit/">Bandit Algorithms</a></li><li><a class="tocitem" href="../online/">Multiplicative Weight Updates</a></li><li><a class="tocitem" href="../qlearning/">Q-Learning</a></li></ul></li><li><span class="tocitem">Deep Learning</span><ul><li><a class="tocitem" href="../hopfield/">Hopfield Networks</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Linear Systems</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Linear Systems</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/varnerlab/VLDataScienceMachineLearningPackage.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/varnerlab/VLDataScienceMachineLearningPackage.jl/blob/main/docs/src/solvers.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Linear-Systems"><a class="docs-heading-anchor" href="#Linear-Systems">Linear Systems</a><a id="Linear-Systems-1"></a><a class="docs-heading-anchor-permalink" href="#Linear-Systems" title="Permalink"></a></h1><p>We provide several techniques for working with linear systems, including eigendecomposition using QR iteration and iterative solvers for linear systems. These solvers are useful for large, sparse systems where direct methods may be inefficient.</p><p>In addition, we provide functionality for solving linear programming problems.</p><article><details class="docstring" open="true"><summary id="VLDataScienceMachineLearningPackage.qriteration"><a class="docstring-binding" href="#VLDataScienceMachineLearningPackage.qriteration"><code>VLDataScienceMachineLearningPackage.qriteration</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">qriteration(A::Array{Float64,2}; maxiter::Int64 = 10, tolerance::Float64 = 1e-9) -&gt; Tuple</code></pre><p>Computes the eigenvalues and eigenvectors of a real matrix <code>A</code> using the QR iteration method.</p><p><strong>Arguments</strong></p><ul><li><code>A::Array{Float64,2}</code>: a real matrix of size <code>n x n</code>.</li><li><code>maxiter::Int64</code>: the maximum number of iterations (default is <code>10</code>).</li><li><code>tolerance::Float64</code>: the tolerance for the stopping criterion (default is <code>1e-9</code>).</li></ul><p><strong>Returns</strong></p><ul><li><code>Tuple</code>: a tuple of two elements: the first element is an array of eigenvalues and the second element is a dictionary of eigenvectors.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/varnerlab/VLDataScienceMachineLearningPackage.jl/blob/60b08b0d460db739ca98a76a4bb47e86a70aed71/src/Eigen.jl#L52-L64">source</a></section></details></article><article><details class="docstring" open="true"><summary id="VLDataScienceMachineLearningPackage.solve"><a class="docstring-binding" href="#VLDataScienceMachineLearningPackage.solve"><code>VLDataScienceMachineLearningPackage.solve</code></a> — <span class="docstring-category">Function</span></summary><section><div><pre><code class="language-julia hljs">solve(A::AbstractMatrix{T}, b::AbstractVector{T}, xₒ::AbstractVector{T}; 
algorithm::AbstractLinearSolverAlgorithm = JacobiMethod(), ϵ::Float64 = 0.01, maxiterations::Int64 = 100) where T &lt;: Number</code></pre><p>The <code>solve</code> function solves the linear system of equations <code>Ax = b</code> using the specified algorithm.  The function returns the solution vector <code>x</code> for each iteration of an iterative method. </p><p><strong>Arguments</strong></p><ul><li><code>A::AbstractMatrix{T}</code>: The system matrix <code>A</code> in the linear system of equations <code>Ax = b</code>.</li><li><code>b::AbstractVector{T}</code>: The right-hand side vector <code>b</code> in the linear system of equations <code>Ax = b</code>.</li><li><code>xₒ::AbstractVector{T}</code>: The initial guess for the solution vector <code>x</code>.</li><li><code>algorithm::AbstractLinearSolverAlgorithm</code>: The algorithm to use to solve the linear system of equations. The default algorithm is <code>JacobiMethod()</code>.</li><li><code>ϵ::Float64</code>: The error tolerance for the iterative method. The default value is <code>1e-6</code>.</li><li><code>maxiterations::Int64</code>: The maximum number of iterations for the iterative method. The default value is <code>1000</code>.</li><li><code>ω::Float64</code>: The relaxation factor for the Successive Over-Relaxation method. The default value is <code>1.0</code>. This parameter is only used if the <code>SuccessiveOverRelaxationMethod</code> algorithm is selected.</li></ul><p><strong>Returns</strong></p><ul><li><code>d::Dict{Int,Array{T,1}}</code>: The solution vector <code>x</code> for each iteration of an iterative method. The keys of the dictionary are the iteration numbers, and the values are the solution vectors at each iteration.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/varnerlab/VLDataScienceMachineLearningPackage.jl/blob/60b08b0d460db739ca98a76a4bb47e86a70aed71/src/Solvers.jl#L171-L189">source</a></section><section><div><pre><code class="language-julia hljs">solve(problem::MyLinearProgrammingProblemModel) -&gt; Dict{String,Any}</code></pre><p>Solves a linear programming problem defined by the <code>MyLinearProgrammingProblemModel</code> instance using the GLPK solver.</p><p><strong>Arguments</strong></p><ul><li>problem::MyLinearProgrammingProblemModel: An instance of MyLinearProgrammingProblemModel holding the data for the problem.</li><li>constraints::Symbol: The type of constraints to apply. Options are :leq (less than or equal to), :geq (greater than or equal to), or :eq (equal to). Default is :leq.</li></ul><p><strong>Returns</strong></p><ul><li>Dict{String,Any}: A dictionary with the following keys:<ul><li>&quot;argmax&quot;: The optimal choice.</li><li>&quot;budget&quot;: The budget at the optimal choice.</li><li>&quot;objective_value&quot;: The value of the objective function at the optimal choice.</li></ul></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/varnerlab/VLDataScienceMachineLearningPackage.jl/blob/60b08b0d460db739ca98a76a4bb47e86a70aed71/src/Solvers.jl#L199-L213">source</a></section><section><div><pre><code class="language-julia hljs">solve(problem::MySimpleCobbDouglasChoiceProblem)</code></pre><p>Solve the Cobb-Douglas choice problem and return the results as a dictionary.</p><p><strong>Arguments</strong></p><ul><li><code>problem::MySimpleCobbDouglasChoiceProblem</code>: the Cobb-Douglas choice problem</li></ul><p><strong>Returns</strong></p><ul><li><code>Dict{String,Any}</code>: a dictionary with the results. The dictionary has the following keys:<ul><li><code>argmax::Array{Float64,1}</code>: the optimal choice of goods</li><li><code>budget::Float64</code>: the budget used</li><li><code>objective_value::Float64</code>: the value of the objective function</li></ul></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/varnerlab/VLDataScienceMachineLearningPackage.jl/blob/60b08b0d460db739ca98a76a4bb47e86a70aed71/src/Solvers.jl#L272-L285">source</a></section><section><div><pre><code class="language-julia hljs">solve(model::MyValueIterationModel, problem::MyMDPProblemModel) -&gt; MyValueFunctionPolicy</code></pre><p>This function solves the MDP problem using value iteration.</p><p><strong>Arguments</strong></p><ul><li><code>model::MyValueIterationModel</code>: the value iteration model</li><li><code>problem::MyMDPProblemModel</code>: the MDP problem model</li></ul><p><strong>Returns</strong></p><ul><li><code>MyValueFunctionPolicy</code>: the value function policy</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/varnerlab/VLDataScienceMachineLearningPackage.jl/blob/60b08b0d460db739ca98a76a4bb47e86a70aed71/src/MDP.jl#L201-L212">source</a></section><section><div><pre><code class="language-julia hljs">solve(model::MyRandomRolloutModel, problem::MyMDPProblemModel, 
    world::MyRectangularGridWorldModel, s::Int64) -&gt; Float64</code></pre><p>This function solves the MDP problem using random rollouts.</p><p><strong>Arguments</strong></p><ul><li><code>model::MyRandomRolloutModel</code>: the random rollout model</li><li><code>problem::MyMDPProblemModel</code>: the MDP problem model</li><li><code>world::MyRectangularGridWorldModel</code>: the world model</li><li><code>s::Int64</code>: the state</li></ul><p><strong>Returns</strong></p><ul><li><code>Float64</code>: the estimated utility value of the state <code>s</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/varnerlab/VLDataScienceMachineLearningPackage.jl/blob/60b08b0d460db739ca98a76a4bb47e86a70aed71/src/MDP.jl#L229-L243">source</a></section><section><div><pre><code class="language-julia hljs">solve(model::AbstractBanditAlgorithmModel; T::Int = 0, world::Function = _null)</code></pre><p>Solve the bandit problem using the given model. </p><p><strong>Arguments</strong></p><ul><li><code>model::AbstractBanditAlgorithmModel</code>: The model to use to solve the bandit problem.</li><li><code>T::Int = 0</code>: The number of rounds to play. Default is 0.</li><li><code>world::Function = _null</code>: The function that returns the reward for a given action. Default is the private <code>_null</code> function.</li></ul><p><strong>Returns</strong></p><ul><li><code>Array{Float64,2}</code>: The rewards for each arm at each round.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/varnerlab/VLDataScienceMachineLearningPackage.jl/blob/60b08b0d460db739ca98a76a4bb47e86a70aed71/src/Bandit.jl#L176-L188">source</a></section><section><div><pre><code class="language-julia hljs">solve(model::AbstractBanditAlgorithmModel, context::AbstractBanditProblemContextModel;
    T::Int = 0, world::Function = _null)</code></pre><p>Solve the contextual bandit problem using the given model and context.</p><p><strong>Arguments</strong></p><ul><li><code>model::MyBinaryVectorArmsEpsilonGreedyAlgorithmModel</code>: The model to use to solve the bandit problem.</li><li><code>context::MyConsumerChoiceBanditContextModel</code>: The context model to use. Must be a subtype of <code>AbstractBanditProblemContextModel</code>.</li><li><code>T::Int = 0</code>: The number of rounds to play. Default is 0.</li><li><code>world::Function = _null</code>: The function that returns the reward for a given action. Default is the private <code>_null</code> function.</li><li><code>startdayindex::Int = 1</code>: The starting time index for the context model. Default is 1. This is useful for time series data.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/varnerlab/VLDataScienceMachineLearningPackage.jl/blob/60b08b0d460db739ca98a76a4bb47e86a70aed71/src/Bandit.jl#L194-L206">source</a></section><section><div><pre><code class="language-julia hljs">function solve(model::MyQLearningModel, environment::T, startstate::Int, maxsteps::Int;
    ϵ::Float64 = 0.2) -&gt; MyQLearningModel where T &lt;: AbstractWorldModel</code></pre><p>Simulate the Q-Learning agent in the given environment starting from the given state for a maximum number of steps.</p><p><strong>Arguments</strong></p><ul><li><code>agent::MyQLearningAgentModel</code>: The Q-Learning agent model.</li><li><code>environment::MyRectangularGridWorldModel</code>: The environment model.</li><li><code>maxsteps::Int</code>: The maximum number of steps to simulate.</li><li><code>δ::Float64 = 0.02</code>: The convergence threshold. Default is 0.02.</li><li><code>worldmodel::Function = _world</code>: The world model function. Default is the private <code>_world</code> function.</li></ul><p><strong>Returns</strong></p><ul><li><code>MyQLearningAgentModel</code>: The updated Q-Learning agent model after simulation.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/varnerlab/VLDataScienceMachineLearningPackage.jl/blob/60b08b0d460db739ca98a76a4bb47e86a70aed71/src/QLearning.jl#L14-L29">source</a></section></details></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../graphs/">« Graphs</a><a class="docs-footer-nextpage" href="../binaryclassification/">Binary Classification »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Friday 5 December 2025 18:31">Friday 5 December 2025</span>. Using Julia version 1.11.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
